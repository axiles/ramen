#!/bin/sh
# Test network transfer of tuples

this_script="$0"
top_src=$(dirname "$this_script")/../../

# In addition to the aggregator site, how many logging sites do we want?
# Must be at least 1.
nb_loggers=2

# How long should we fill up with data before the functions are stopped.
# In seconds.
logs_for=60000

# hit_rate = logs per seconds output by each logger
hit_rate=1

. "$top_src/tests/lib.sh"

# Merely runs the logs generator in one instance and aggregate the entries
# in another. The aggregator is the "master" that will be forwarded logs to.
# Both run on a single machine but with different $RAMEN_DIR
#
# We rely on envvars to know which role this instance of the test script
# has to play and on which port to contact the master.
# By default I am the master:

if test -z "$master_port"; then
  r=$(rand 64511)
  master_port=$((1024+$r))
  be_master=yes
  ramen_site=aggregator
  master_ramen_dir="$RAMEN_DIR"
  log "I'm the aggregator, listening to forwarded tuples at port $master_port"
else
  # mktemp created a directory that we are not going to use:
  rmdir "$RAMEN_DIR"
  be_master=no
  test -n "$ramen_site" || fail 'master should have set ramen_site'
  test -n "$master_ramen_dir" || fail 'master should have set master_ramen_dir'
  log "I'm $ramen_site"
fi
export RAMEN_DIR="$master_ramen_dir/$ramen_site"

rc_version=v16
services_version=v2
archivist_version=v7

if test "$be_master" = yes; then
  log "Run the confserver"
  "$ramen" confserver --no-examples --master=aggregator --site="$ramen_site" --insecure --debug &
  confserver_pid=$!
  at_exit "echo 'Killing confserver'; kill '$confserver_pid'"

  log "Run the tunneling server..."
  "$ramen" tunneld --master=aggregator --site="$ramen_site" --port "$master_port" --confserver=localhost &
  tunneld_pid=$!
  at_exit "echo 'Killing tunneld'; kill '$tunneld_pid'"

  log "Run the alerter..."
  "$ramen" alerter --master=aggregator --site="$ramen_site" --confserver=localhost --debug &
  alerter_pid=$!
  at_exit "echo 'Killing alerter'; kill '$alerter_pid'"

  log "declare all the services..."
  # TODO: version number from ramen_versions.sh?
  services="$RAMEN_DIR/services/$services_version/services"
  mkdir -p $(dirname $services)
  echo '{' > $services
  echo '  "aggregator" => {' >> $services
  echo '    "tunneld" => { host="127.0.0.1"; port='"$master_port"' };' >> $services
  echo '  };' >> $services
  # Also declare other hosts that are not running any service so that
  # Services.all_hosts knows about them (improves logs on aggregator)
  for h in $(seq 1 $nb_loggers); do
    name="logger$h"
    echo '  "'"$name"'" => {};' >> $services
  done
  echo '}' >> $services

  # Must be done before archivist is run:
  log "create archivist user conf..."
  mkdir -p "$RAMEN_DIR/archivist/$archivist_version/"
  # The idea behind this conf is that aggregated values are kept for a
  # longer time while 1min aggregate is not kept, but could be reconstructed
  # from raw logs (thus allowing to test distributed replay)
  cat > "$RAMEN_DIR/archivist/$archivist_version/config" <<EOF
{
  size_limit = 8000000000;
  retentions = {
    "logs/http" => { duration = 43200 };
    "10mins/http" => { duration = 259200 };
    "1hour/http" => { duration = 2592000 };
    "*/stats" => { duration = 0 };
  }
}
EOF

  log "Run the http, compilation and choreographer services"

  "$ramen" httpd --master=aggregator --site="$ramen_site" --confserver=localhost --url=http://localhost:29380 --graphite=graphite/ &
  httpd_pid=$!
  at_exit "echo 'Killing httpd'; kill '$httpd_pid'"

  "$ramen" precompserver --master=aggregator --site="$ramen_site" --confserver=localhost &
  precompserver_pid=$!
  at_exit "echo 'Killing precompserver'; kill '$precompserver_pid'"

  "$ramen" choreographer --master=aggregator --site="$ramen_site" --confserver=localhost --debug &
  choreographer_pid=$!
  at_exit "echo 'Killing choreographer'; kill '$choreographer_pid'"

  "$ramen" replayer --master=aggregator --site="$ramen_site" --confserver=localhost --debug &
  replay_service_pid=$!
  at_exit "echo 'Killing replayer'; kill '$replay_service_pid'"

  log "Compiling programs via the confserver..."

  # Note: _absolute_ bin paths are stored in the RC to help filesyncer:
  root="$PWD/examples/programs/monitoring/generated"
  "$ramen" compile --confserver=localhost "$root/logs.ramen"              --as logs
  "$ramen" compile --confserver=localhost "$root/aggregated.ramen"        --as aggregated
  "$ramen" compile --confserver=localhost "$root/errors.ramen"            --as errors
  "$ramen" compile --confserver=localhost "$root/alerts/error_rate.alert" --as alerts/error_rate
  "$ramen" compile --confserver=localhost "$root/alerts/resp_time.alert"  --as alerts/resp_time

  log "Starting programs..."
  export RAMEN_REPORT_PERIOD=15
  "$ramen" run --confserver=localhost 'logs'              --master=aggregator --on-site="logger*"    --debug -p hit_rate=$hit_rate
  "$ramen" run --confserver=localhost 'aggregated#1min'   --master=aggregator --on-site="aggregator" --debug -p time_period=60
  "$ramen" run --confserver=localhost 'aggregated#10mins' --master=aggregator --on-site="aggregator" --debug -p time_period=600
  "$ramen" run --confserver=localhost 'aggregated#1hour'  --master=aggregator --on-site="aggregator" --debug -p time_period=3600
  "$ramen" run --confserver=localhost 'errors'            --master=aggregator --on-site="aggregator" --debug
  "$ramen" run --confserver=localhost 'alerts/error_rate' --master=aggregator --on-site="aggregator" --debug
  "$ramen" run --confserver=localhost 'alerts/resp_time'  --master=aggregator --on-site="aggregator" --debug

else

  log "Linking config files from aggregator" ;

  mkdir -p "$RAMEN_DIR/services/$services_version/"
  ln "$RAMEN_DIR/../aggregator/services/$services_version/services" \
     "$RAMEN_DIR/services/$services_version/"
fi

"$ramen" execompserver --master=aggregator --confserver=localhost --site="$ramen_site" --debug &
execompserver_pid=$!
at_exit "echo 'Killing execompserver'; kill '$execompserver_pid'"

"$ramen" supervisor --master=aggregator --confserver=localhost --site="$ramen_site" --debug &
supervisor_pid=$!
at_exit "echo 'Killing supervisor'; kill '$supervisor_pid'"

"$ramen" gc --loop=15 --master=aggregator --confserver=localhost --site="$ramen_site" &
gc_pid=$!
at_exit "echo 'Killing gc'; kill '$gc_pid'"

# Archivist --reconf and --stats must also run everywhere, and fully on master
if test "$be_master" = yes; then
  "$ramen" archivist --master=aggregator --site="$ramen_site" --loop=5 --confserver=localhost --reconf --allocs &
  archivist_pid=$!
else
  "$ramen" archivist --master=aggregator --site="$ramen_site" --loop=5 --confserver=localhost --reconf &
  archivist_pid=$!
fi
at_exit "echo 'Killing archivist'; kill '$archivist_pid'"

if test "$be_master" = yes; then

  # Run the other instances
  for h in $(seq 1 $nb_loggers); do
    name="logger$h"
    /usr/bin/env \
      master_port="$master_port" ramen_site="$name" \
      master_ramen_dir="$master_ramen_dir" \
      "$this_script" &
    logger_pid=$!
    at_exit "echo 'Killing $name'; kill '$logger_pid'"
  done
fi

if test "$be_master" = yes; then
  # Let's log full speed for some time...
  echo "Logging for $logs_for seconds..."
  sleep "$logs_for"

  echo "Stopping the functions."
  "$ramen" kill --master=aggregator '*'

  # Wait until we have "enough" data
  echo "Waiting for the kills..."
fi

wait

echo "Stopping..."
