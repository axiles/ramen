-- vim: ft=sql expandtab
-- Benchmark light on operations but with many small functions passing data
-- around.

DEFINE producer1 AS
  YIELD sum globally 1 AS s, random AS r; -- at full speed

DEFINE producer2 AS
  YIELD sum globally 1 + 100 AS s, random AS r;

DEFINE producer3 AS
  YIELD sum globally 1 + 1000 AS s, random AS r;

DEFINE consumer1 AS
  FROM producer1, producer2, producer3
  SELECT sum globally 1 AS _my_s, "c1" AS me, min s, max s, min r, max r
  COMMIT AFTER _my_s % 10 = 0;

DEFINE consumer2 AS
  FROM producer1, producer2, producer3 MERGE ON s
  SELECT sum globally 1 AS _my_s, "c2" AS me, min s, max s, min r, max r
  COMMIT AFTER _my_s % 10 = 0;

DEFINE sink AS
  FROM consumer1, consumer2
  SELECT me AS parent, max_r - min_r AS r_range;

-- And then: select from all monitoring the total cpu, ram and output tuples,
-- group by function name, and report every 10s:

DEFINE metamon AS
  LISTEN FOR INSTRUMENTATION FROM *;

DEFINE benchmark AS
  FROM metamon
  SELECT
    worker,
    min start AS _min_start, max start AS start,
    out.start - _min_start AS duration,
    max tuples_out - min tuples_out AS outs,
    out.outs / duration AS avg_tuples_per_secs,
    (max wait_out - min wait_out) / duration AS wait_out_ratio,
    (max wait_in - min wait_in) / duration AS wait_in_ratio,
    (max cpu - min cpu) / out.outs AS avg_cpu_per_tuple,
    max ram
  GROUP BY worker
  COMMIT BEFORE duration > 30;
